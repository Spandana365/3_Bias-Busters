# 3_Bias-Busters
Our project analyzes gender bias in AI-powered hiring systems by evaluating two datasets—one biased and one unbiased—using explainability tools like LIME and SHAP. We implement fairness metrics with Fairlearn and AI Fairness 360 to quantify bias and apply bias mitigation techniques to improve hiring decisions. The goal is to ensure a fair, transparent, and unbiased AI-driven recruitment process.
